{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To rerun any S-LOCAL network you need a minimum of 32GB of RAM/VRAM memory on the device used for training\n",
    "- Average time to run a 100 epoch on a Nvidia Tesla V100 GPU is 20 minutes\n",
    "- A faster implementation of the Locally Connected Layer is available in the Keras API : \n",
    "- https://keras.io/api/layers/locally_connected_layers/locall_connected2d/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_PATH = \".\"\n",
    "DOWNLOAD_DATA = False\n",
    "\n",
    "# To use google colab processing uncomment following lines\n",
    "\n",
    "#INIT_PATH = \"MyDrive/inference_and_learning\"\n",
    "#from google.colab import drive\n",
    "#MOUNT_PATH = \"/content/drive\"\n",
    "#drive.mount(MOUNT_PATH)\n",
    "#INIT_PATH = MOUNT_PATH + \"/\" + INIT_PATH\n",
    "#DOWNLOAD_DATA = True\n",
    "\n",
    "# To train LOCAL change to True\n",
    "LOCAL_TRAIN = False \n",
    "\n",
    "\n",
    "# To avoid out of memory error, adjust \n",
    "NUM_THREADS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path,sys\n",
    "sys.path.append(INIT_PATH)\n",
    "\n",
    "import networks as nnets\n",
    "import importlib\n",
    "importlib.reload(nnets)\n",
    "import pandas as pd, torch\n",
    "from typing import Tuple, List\n",
    "import torchvision\n",
    "import torch\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "torch.set_default_dtype(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \".\" # Path to data folder\n",
    "if (DOWNLOAD_DATA):\n",
    "    torchvision.datasets.CIFAR10(root=DATA_PATH + '/data', download=True)\n",
    "    torchvision.datasets.CIFAR100(root=DATA_PATH + '/data', download=True)\n",
    "    torchvision.datasets.SVHN(root=DATA_PATH +'/data', download=True)\n",
    "\n",
    "    torchvision.datasets.CIFAR10(root=DATA_PATH +'/data', download=True,train = False)\n",
    "    torchvision.datasets.CIFAR100(root=DATA_PATH +'/data', download=True ,train = False) \n",
    "    torchvision.datasets.SVHN(root=DATA_PATH +'/data', download=True, split = \"test\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL: optimization of parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may use this script to test different hyperparameters\n",
    "Load the network description in the file files/optim.json\n",
    "The file is a json file with the following structure :\n",
    "```json\n",
    "{\n",
    "    \"optim\":{ // Hyperparameters to optimize\n",
    "        \"model\":{ // Hyperparameters to optimize for the model\n",
    "            \"S-LOCAL\":{ // Model you want to optimize hyperparameters on \n",
    "                \"hidden_size\":[64,128,256,512], // List of values to test\n",
    "                \"dropout\":[0.1,0.2,0.3,0.4,0.5] // List of values to test\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"networks\":{ // List of networks to test\n",
    "        \"S-LOCAL-64-0.1\":{ // Name of the network\n",
    "            //add the network default description here\n",
    "        }\n",
    "    },\n",
    "    \"results\":{ // Results of the optimization\n",
    "        \"S-LOCAL-64-0.1\":{ //Name of the network\n",
    "            \"best\":{ \n",
    "                // Best hyperparameters found\n",
    "            },\n",
    "            \"accuracy\":0.9 // Accuracy of the best hyperparameters\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from time import sleep\n",
    "\n",
    "optimer  = lambda : nnets.NetworkOptim(optim[\"optim\"],DATA_PATH,epoch=100,verbose = True,very_verbose = False)\n",
    "\n",
    "optim = json.load(open(INIT_PATH+\"/files/optim.json\"))\n",
    "Thread = 4\n",
    "list_to_do = [(key,item) for key,item in optim[\"networks\"].items() if\n",
    "              key not in optim[\"results\"] and\n",
    "              not (not LOCAL_TRAIN and item[\"model\"][\"name\"] in [\"S-LOCAL\",\"D-LOCAL\"])]\n",
    "threads = [nnets.OptimThread(optim,list_to_do.pop(0),optimer()) for _ in range(Thread)]\n",
    "for i in threads:\n",
    "    i.start()\n",
    "    sleep(1)\n",
    "\n",
    "while len(threads) != 0:\n",
    "    sleep(10)\n",
    "    for i in threads:\n",
    "        if i.is_alive():\n",
    "            continue\n",
    "        threads.remove(i)\n",
    "        if len(list_to_do) == 0:\n",
    "            continue\n",
    "        threads.append(nnets.OptimThread(optim,list_to_do.pop(0),optimer()))\n",
    "        threads[-1].start()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing the paper\n",
    "\n",
    "### Table 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy updated every 100 epochs\n",
      "GPU available: 0.806879232GB on 8.353153024GB\n",
      "\n",
      "     Model     |   Optimizer   |    Dataset    ||    accuracy   \n",
      "---------------|---------------|---------------||----------------\n",
      "\n",
      "\n",
      "Thread    ||   Thread-5  |   Thread-6  |   Thread-7  ||\n",
      "----------||-------------|-------------|-------------||\n",
      "Model     || S-CONV      | 3-FC        | S-FC        ||\n",
      "Dataset   || CIFAR-10    | CIFAR-10    | CIFAR-10    ||\n",
      "Optimizer || SGD         | SGD         | SGD         ||\n",
      "cuda      || cuda        | cuda        | cuda        ||\n",
      "epoch max || 4000        | 4000        | 4000        ||\n",
      "Size      || 255.80 M    | 249.79 M    | 230.67 M    ||\n",
      "----------||-------------|-------------|-------------||\n",
      "epoch,acc || 731  66.60% | 885  59.38% | 963  59.54% ||"
     ]
    }
   ],
   "source": [
    "RETRAIN = False\n",
    "table2 = pd.read_csv(INIT_PATH+\"/files/table2.csv\")\n",
    "table2_net = json.load(open(INIT_PATH+\"/files/table2.json\"))\n",
    "trainer = nnets.ThreadedTrainer(\n",
    "    NUM_THREADS,\n",
    "    DATA_PATH=\".\",\n",
    "    SAVE_TABLE_PATH=INIT_PATH+\"/files/table2.csv\",\n",
    "    SAVE_NETWORK_PATH= INIT_PATH+\"/networks_saved/\",\n",
    "    SAVE_FIGURE3_PATH= INIT_PATH + \"/files/figure3.json\",)\n",
    "\n",
    "for dataset in [\"CIFAR-10\",\"CIFAR-100\",\"SVHN\"]:\n",
    "    for l in range(len(table2)):\n",
    "        csv_line = table2.iloc[l].to_dict()\n",
    "        if csv_line[\"train\"]==False or (str(csv_line[dataset]) in \"nan\") or (LOCAL_TRAIN==False and csv_line[\"Model\"] in [\"S-LOCAL\",\"D-LOCAL\"]):\n",
    "            continue\n",
    "        ID = \"_\".join([csv_line[i] for i in [\"Model\",\"Training_Method\"]]+[dataset])\n",
    "        if not RETRAIN and os.path.isfile(INIT_PATH+\"/networks_saved/\"+ID+\".pt\"):\n",
    "            continue\n",
    "        network = table2_net[ID]\n",
    "        trainer.add(ID,network,network[\"model\"] == \"S-FC\" and network[\"training_method\"] == \"B-lasso(B=50)\")\n",
    "        \n",
    "print(\"Starting training\")\n",
    "trainer.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 3\n",
    "We can reuse result saved while training table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaenabled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e63968e63be298c54f0ef6fc5f307c0f048e4cbeb5634e9b9b715fe9de39ba43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
