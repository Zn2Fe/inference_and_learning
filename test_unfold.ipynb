{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (3903171048.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if ((buff = True)==True):\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "if ((buff = True)==True):\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training_Method</th>\n",
       "      <th>CIFAR-10</th>\n",
       "      <th>CIFAR-100</th>\n",
       "      <th>SVHN</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S-CONV</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S-LOCAL</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP (Neyshabur et al. 2019)</td>\n",
       "      <td>SGD</td>\n",
       "      <td>58.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.3%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP (Mukkamala and Hein 2017)</td>\n",
       "      <td>ADAM_RMS</td>\n",
       "      <td>72.2%</td>\n",
       "      <td>39.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP (Mocanu et al. 2018)</td>\n",
       "      <td>SET</td>\n",
       "      <td>74.84%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP (Urban et al. 2017)</td>\n",
       "      <td>deep_conv_teacher</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP (Lin et al. 2016)</td>\n",
       "      <td>ZAE</td>\n",
       "      <td>78.62%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3-FC</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S-FC</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S-FC</td>\n",
       "      <td>B-lasso(B=0)</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S-FC</td>\n",
       "      <td>B-lasso(B=10)</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S-FC</td>\n",
       "      <td>B-lasso(B=50)</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./files/table2.csv\").to_html()\n",
    "data = HTML(data)\n",
    "display( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-45 (log_test)\n",
      "Thread-46 (log_test)\n",
      "Thread-47 (log_test)\n",
      "Thread-48 (log_test)\n",
      "Thread-49 (log_test)\n",
      "Thread-50 (log_test)\n",
      "Thread-51 (log_test)\n",
      "Thread-52 (log_test)\n",
      "Thread-53 (log_test)\n",
      "Thread-54 (log_test)\n",
      "testtesttesttesttesttesttesttesttesttest"
     ]
    }
   ],
   "source": [
    "def log_test():\n",
    "    logger.log_progress(\"test\")\n",
    "\n",
    "a = [Thread(target=log_test) for i in range(10)]\n",
    "\n",
    "for i in a :\n",
    "    print(i.name)\n",
    "    i.start()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping S-LOCAL_SGD_CIFAR-10 as it is a localy connected network\n",
      "Skipping S-LOCAL_SGD_CIFAR-100 as it is a localy connected network\n",
      "Skipping S-LOCAL_SGD_SVHN as it is a localy connected network\n",
      "\n",
      "Milestone : S-CONV_SGD_CIFAR-10 : Training Start\n",
      "\n",
      "Milestone : 3-FC_SGD_CIFAR-10 : Training Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9 (trainThread):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuna/anaconda3/envs/cudaenabled/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yuna/anaconda3/envs/cudaenabled/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuna/Documents/inference_and_learning/inference_and_learning_final_project/networks/__init__.py\", line 270, in trainThread\n",
      "    key,net,non_zero = self._pd_dict.pop(0)\n",
      "  File \"/home/yuna/Documents/inference_and_learning/inference_and_learning_final_project/networks/__init__.py\", line 243, in train\n",
      "    loss.backward()\n",
      "  File \"/home/yuna/anaconda3/envs/cudaenabled/lib/python3.10/site-packages/torch/_tensor.py\", line 488, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/yuna/anaconda3/envs/cudaenabled/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 197, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 488.00 MiB (GPU 0; 7.78 GiB total capacity; 2.15 GiB already allocated; 235.81 MiB free; 2.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Exception in thread Thread-10 (trainThread):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuna/anaconda3/envs/cudaenabled/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yuna/anaconda3/envs/cudaenabled/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuna/Documents/inference_and_learning/inference_and_learning_final_project/networks/__init__.py\", line 270, in trainThread\n",
      "    key,net,non_zero = self._pd_dict.pop(0)\n",
      "  File \"/home/yuna/Documents/inference_and_learning/inference_and_learning_final_project/networks/__init__.py\", line 243, in train\n",
      "    loss.backward()\n",
      "  File \"/home/yuna/anaconda3/envs/cudaenabled/lib/python3.10/site-packages/torch/_tensor.py\", line 488, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/yuna/anaconda3/envs/cudaenabled/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 197, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 7.78 GiB total capacity; 2.13 GiB already allocated; 235.81 MiB free; 2.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished !\n",
      "                            Model    Training_Method CIFAR-10 CIFAR-100  \\\n",
      "0                          S-CONV                SGD       0%        0%   \n",
      "1                         S-LOCAL                SGD       0%        0%   \n",
      "2     MLP (Neyshabur et al. 2019)                SGD    58.1%       NaN   \n",
      "3   MLP (Mukkamala and Hein 2017)           ADAM_RMS    72.2%     39.3%   \n",
      "4        MLP (Mocanu et al. 2018)                SET   74.84%       NaN   \n",
      "5         MLP (Urban et al. 2017)  deep_conv_teacher    74.3%       NaN   \n",
      "6           MLP (Lin et al. 2016)                ZAE   78.62%       NaN   \n",
      "7                            3-FC                SGD       0%        0%   \n",
      "8                            S-FC                SGD       0%        0%   \n",
      "9                            S-FC       B-lasso(B=0)       0%        0%   \n",
      "10                           S-FC      B-lasso(B=10)       0%        0%   \n",
      "11                           S-FC      B-lasso(B=50)       0%        0%   \n",
      "\n",
      "     SVHN  train  \n",
      "0      0%   True  \n",
      "1      0%   True  \n",
      "2   84.3%  False  \n",
      "3     NaN  False  \n",
      "4     NaN  False  \n",
      "5     NaN  False  \n",
      "6     NaN  False  \n",
      "7      0%   True  \n",
      "8      0%   True  \n",
      "9      0%   True  \n",
      "10     0%   True  \n",
      "11     0%   True  \n"
     ]
    }
   ],
   "source": [
    "INIT_PATH = \".\"\n",
    "DOWNLOAD_DATA = False\n",
    "\n",
    "# To use google colab processing uncomment following lines\n",
    "\n",
    "#INIT_PATH = \"MyDrive/inference_and_learning\"\n",
    "#from google.colab import drive\n",
    "#MOUNT_PATH = \"/content/drive\"\n",
    "#drive.mount(MOUNT_PATH)\n",
    "#INIT_PATH = MOUNT_PATH + \"/\" + INIT_PATH\n",
    "#DOWNLOAD_DATA = True\n",
    "\n",
    "# To train LOCAL change to True\n",
    "LOCAL_TRAIN = False \n",
    "import os.path,sys\n",
    "sys.path.append(INIT_PATH)\n",
    "\n",
    "import networks as nnets\n",
    "import pandas as pd, torch\n",
    "from typing import Tuple, List\n",
    "import torchvision\n",
    "import torch\n",
    "import json\n",
    "torch.set_default_dtype(torch.float16)\n",
    "\n",
    "table2 = pd.read_csv(INIT_PATH+\"/files/table2.csv\")\n",
    "table2_net = json.load(open(INIT_PATH+\"/files/table2.json\"))\n",
    "RETRAIN = True\n",
    "\n",
    "if RETRAIN :\n",
    "    trainer = nnets.ThreadedTrainer(\".\",INIT_PATH+\"/networks_saved/\",INIT_PATH + \"/files/figure3.json\")\n",
    "    for dataset in [\"CIFAR-10\",\"CIFAR-100\",\"SVHN\"]:\n",
    "        for l in range(len(table2)):\n",
    "            csv_line = table2.iloc[l].to_dict()\n",
    "            if csv_line[\"train\"]==False or (str(csv_line[dataset]) == \"nan\"):\n",
    "                continue\n",
    "            ID = \"_\".join([csv_line[i] for i in [\"Model\",\"Training_Method\"]]+[dataset])\n",
    "            network = table2_net[ID]\n",
    "            if network[\"model\"][\"name\"] in [\"S-LOCAL\",\"D-LOCAL\"]:\n",
    "                print(f\"Skipping {ID} as it is a localy connected network\")\n",
    "                continue\n",
    "            \n",
    "            save_model_0 = False\n",
    "            if network[\"model\"] == \"S-FC\" and network[\"training_method\"] == \"B-lasso(B=50)\":\n",
    "                save_model_0 = True\n",
    "            trainer.append(ID,network,save_model_0)\n",
    "    res = trainer(2)\n",
    "    for key,item in res.items() :\n",
    "        table2.loc[table2[\"Model\"] == key.split(\"_\")[0] and table2[\"Training_Method\"] == key.split(\"_\")[1] ,key.split(\"_\")[2]] = item\n",
    "    table2.to_csv(INIT_PATH+\"/files/table2.csv\",index=False)\n",
    "print(table2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaenabled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e63968e63be298c54f0ef6fc5f307c0f048e4cbeb5634e9b9b715fe9de39ba43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
